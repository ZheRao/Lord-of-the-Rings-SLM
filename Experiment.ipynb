{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from operator import itemgetter\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from update_utilities import update_utilities_class\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Examining the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lord-of-the-rings-processed.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the book - 3729059 characters\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of the book - {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Music of the Ainur There was Eru, the One, who in Arda is called lluvatar; and he made first the\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '®', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '\"', \"'\", '®', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "common = r\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ();:.!?-,\"\n",
    "special = [char for char in chars if char not in list(common)]\n",
    "print(special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\",\" \")\n",
    "text = text.replace(\"  \", \" \")\n",
    "text = text.replace(\"®\", \"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‘', '’', '“', '”', ',', ';', ':', '!', '?']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_char = list(itemgetter(*[6,7,8,9])(special))\n",
    "special_char.extend([\",\",\";\",\":\",\"!\",\"?\"])\n",
    "special_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‘', '“']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_space_after = list(itemgetter(*[0,2])(special_char))\n",
    "no_space_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['’', '”', ',', ';', ':', '!', '?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_space_before = list(itemgetter(*set(range(len(special_char)))-set([0,2]))(special_char))\n",
    "no_space_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace such as <' sss> to <'sss>\n",
    "for s in no_space_after:\n",
    "    text = text.replace(s+\" \", s)\n",
    "\n",
    "# replace such as <s ,> to <s,>\n",
    "for s in no_space_before:\n",
    "    text = text.replace(\" \"+s,s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the use of quotation marks\n",
    "text = text.replace('\"',\"'\")\n",
    "text = text.replace('‘',\"'\")\n",
    "text = text.replace('’',\"'\")\n",
    "text = text.replace('“',\"'\")\n",
    "text = text.replace('”',\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lord-of-the-rings-processed.txt\",\"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Create Dictionary and Tokenize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', \"'\", '—']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "common = r\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ();:.!?-,\"\n",
    "special = [char for char in chars if char not in list(common)]\n",
    "print(special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "# encode_char = {char:i for i, char in enumerate(chars)}\n",
    "# decode_char = {i:char for i, char in enumerate(chars)}\n",
    "# print(len(encode_char))\n",
    "# vocab_size = len(encode_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('saved_encoder_dict.pkl','wb') as f:\n",
    "#     pickle.dump(encode_char,f)\n",
    "\n",
    "# with open('saved_decoder_dict.pkl','wb') as f:\n",
    "#     pickle.dump(decode_char,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "with open('saved_encoder_dict.pkl','rb') as f:\n",
    "    encode_char = pickle.load(f)\n",
    "\n",
    "with open('saved_decoder_dict.pkl','rb') as f:\n",
    "    decode_char = pickle.load(f)\n",
    "\n",
    "print(len(encode_char))\n",
    "vocab_size = len(encode_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda string: [encode_char[s] for s in string]\n",
    "decode = lambda nums: ''.join([decode_char[n] for n in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 54, 55, 65, 0, 55, 65, 0, 53, 61, 61, 50]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"This is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0?wXG'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([8,20,69,44,27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Load data and construct batches + dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**take percentage of text from each book as validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_utilities_class(file_name=\"general_functions.py\",current_path=os.getcwd()).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_functions import HelperFunctionsClass\n",
    "h = HelperFunctionsClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "book1_train, book1_val, end_idx = h.train_test_split(text=text,ending=\"and an end was come for the Eldar of story and of song.\",ratio=0.85,starting_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "book2_train, book2_val, end_idx = h.train_test_split(text=text, ending=\"and handed him the tobacco-jar.\",ratio=0.85,starting_idx=end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "book3_train, book3_val, end_idx = h.train_test_split(text=text, ending=\"THE RETURN OF THE KING.\",ratio=0.85,starting_idx=end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "book4_train, book4_val, end_idx = h.train_test_split(text=text, ending=\"was alive but taken by the Enemy.\",ratio=0.85,starting_idx=end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book5_train, book5_val, end_idx2 = h.train_test_split(text=text, ending=\"I'm back,' he said.\",ratio=0.85,starting_idx=end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  book3_train + book4_train + book5_train + book2_train + book1_train\n",
    "val_data = book3_val + book4_val + book5_val + book2_val + book1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3729058"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data + val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = torch.tensor(encode(train_data))\n",
    "val_data2 = torch.tensor(encode(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3170090, 558968)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data2), len(val_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_utilities_class(file_name=\"custom_text_dataset.py\",current_path=os.getcwd()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_text_dataset import slideTokenizedTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 512\n",
    "\n",
    "train_dataset = slideTokenizedTextDataset(full_txt = train_data2,\n",
    "                                                 block_size = block_size)\n",
    "\n",
    "val_dataset = slideTokenizedTextDataset(full_txt = val_data2,\n",
    "                                               block_size = block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169578, 558456)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_num_samples = 500000\n",
    "train_sampler = torch.utils.data.RandomSampler(train_dataset,replacement=False,num_samples=train_num_samples)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=batch_size,drop_last=True,sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num_samples = 100000\n",
    "val_sampler = torch.utils.data.RandomSampler(val_dataset,replacement=False,num_samples=val_num_samples)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,batch_size=batch_size,sampler=val_sampler,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7812, 1562)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_utilities_class(file_name=\"Transformer.py\",current_path=os.getcwd()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Transformer\n",
    "transformer = Transformer.TransformerClass(vocab_size=vocab_size,emb_dim=512,n_layer=8,num_heads=8,block_size=block_size,\n",
    "                               dropout_rate_attention=0.1,dropout_rate_ff=0.2,dropout_rate_pos_enc=0.1, \n",
    "                               is_decoder = True, ff_multiplier = 4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.28 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(round(sum(p.numel() for p in transformer.parameters())/1e6,2), 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load(\"base_line_GPT stats/base_line_GPT weights/base_line_GPT_last.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied, now the file is available to import from the destinated path\n"
     ]
    }
   ],
   "source": [
    "# update_utilities_class(file_name=\"loss_functions.py\",current_path=os.getcwd()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist in destination folder, it is now removed\n",
      "File copied, now the file is available to import from the destinated path\n"
     ]
    }
   ],
   "source": [
    "# update_utilities_class(file_name=\"train_test_loop.py\",current_path=os.getcwd()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_test_loop import train_test_loop_class\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(),lr=1e-5)\n",
    "overwrite=False\n",
    "\n",
    "train_loop = train_test_loop_class(model=transformer,train_loader=train_dataloader,val_loader=val_dataloader,test_loader=None, epochs=1, print_every_n_batch=500,\n",
    "                                   device=device,model_name=\"base_line_GPT\",optimizer=optimizer,calculate_accuracy=False,overwrite_message=overwrite, problem_type = \"Multiclass Classification\",\n",
    "                                   update_loss_fn=False, print_result = True, print_full = False, lr_rate_tuning=False,clip_batch=False,clip_batch_size=20,lr_start=-5,lr_end=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2924fab85d6f406492028fdaf5106505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500 / 7812 || Average per-Batch Training Loss: 0.4937 || Average per-Batch Validation Loss: 1.4784\n",
      "Batch: 1000 / 7812 || Average per-Batch Training Loss: 0.4918 || Average per-Batch Validation Loss: 1.4838\n",
      "Batch: 1500 / 7812 || Average per-Batch Training Loss: 0.4908 || Average per-Batch Validation Loss: 1.4858\n",
      "Batch: 2000 / 7812 || Average per-Batch Training Loss: 0.4887 || Average per-Batch Validation Loss: 1.4871\n",
      "Batch: 2500 / 7812 || Average per-Batch Training Loss: 0.4873 || Average per-Batch Validation Loss: 1.4923\n",
      "Batch: 3000 / 7812 || Average per-Batch Training Loss: 0.4854 || Average per-Batch Validation Loss: 1.4957\n",
      "Batch: 3500 / 7812 || Average per-Batch Training Loss: 0.4841 || Average per-Batch Validation Loss: 1.4998\n",
      "Batch: 4000 / 7812 || Average per-Batch Training Loss: 0.4829 || Average per-Batch Validation Loss: 1.5020\n",
      "Batch: 4500 / 7812 || Average per-Batch Training Loss: 0.4807 || Average per-Batch Validation Loss: 1.5055\n",
      "Batch: 5000 / 7812 || Average per-Batch Training Loss: 0.4794 || Average per-Batch Validation Loss: 1.5102\n",
      "Batch: 5500 / 7812 || Average per-Batch Training Loss: 0.4781 || Average per-Batch Validation Loss: 1.5148\n",
      "Batch: 6000 / 7812 || Average per-Batch Training Loss: 0.4768 || Average per-Batch Validation Loss: 1.5175\n",
      "Batch: 6500 / 7812 || Average per-Batch Training Loss: 0.4748 || Average per-Batch Validation Loss: 1.5186\n",
      "Batch: 7000 / 7812 || Average per-Batch Training Loss: 0.4735 || Average per-Batch Validation Loss: 1.5222\n",
      "Batch: 7500 / 7812 || Average per-Batch Training Loss: 0.4719 || Average per-Batch Validation Loss: 1.5266\n",
      "Batch: 7812 / 7812 || Average per-Batch Training Loss: 0.4709 || Average per-Batch Validation Loss: 1.5264\n",
      "\n",
      " All Done\n",
      "\n",
      "Overall training took 1.62 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loop.overwrite_message = False\n",
    "# optimizer = torch.optim.AdamW(transformer.parameters(),lr=5e-6)\n",
    "# train_loop.optimizer = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh the sampling\n",
    "train_loop.train_loader = train_dataloader\n",
    "train_loop.val_loader = val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
