{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from operator import itemgetter\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Examining the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lord-of-the-rings-processed.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the book - 3729059 characters\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of the book - {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Music of the Ainur There was Eru, the One, who in Arda is called lluvatar; and he made first the\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '®', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '\"', \"'\", '®', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "common = r\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ();:.!?-,\"\n",
    "special = [char for char in chars if char not in list(common)]\n",
    "print(special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\",\" \")\n",
    "text = text.replace(\"  \", \" \")\n",
    "text = text.replace(\"®\", \"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‘', '’', '“', '”', ',', ';', ':', '!', '?']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_char = list(itemgetter(*[6,7,8,9])(special))\n",
    "special_char.extend([\",\",\";\",\":\",\"!\",\"?\"])\n",
    "special_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‘', '“']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_space_after = list(itemgetter(*[0,2])(special_char))\n",
    "no_space_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['’', '”', ',', ';', ':', '!', '?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_space_before = list(itemgetter(*set(range(len(special_char)))-set([0,2]))(special_char))\n",
    "no_space_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace such as <' sss> to <'sss>\n",
    "for s in no_space_after:\n",
    "    text = text.replace(s+\" \", s)\n",
    "\n",
    "# replace such as <s ,> to <s,>\n",
    "for s in no_space_before:\n",
    "    text = text.replace(\" \"+s,s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the use of quotation marks\n",
    "text = text.replace('\"',\"'\")\n",
    "text = text.replace('‘',\"'\")\n",
    "text = text.replace('’',\"'\")\n",
    "text = text.replace('“',\"'\")\n",
    "text = text.replace('”',\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lord-of-the-rings-processed.txt\",\"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Create Dictionary and Tokenize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', \"'\", '—']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "common = r\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ();:.!?-,\"\n",
    "special = [char for char in chars if char not in list(common)]\n",
    "print(special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "encode_char = {char:i for i, char in enumerate(chars)}\n",
    "decode_char = {i:char for i, char in enumerate(chars)}\n",
    "print(len(encode_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda string: [encode_char[s] for s in string]\n",
    "decode = lambda nums: ''.join([decode_char[n] for n in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 54, 55, 65, 0, 55, 65, 0, 53, 61, 61, 50]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"This is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4OL—L'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([12, 35, 32, 73, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Load data and construct batches + dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3729059])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e filled with gladness; but because of the roaring of the sea they felt a great unquiet. And they observed the winds and the \n",
      "air, and the matters of which Arda was made, of iron and stone and silver and gold and many substances: but of all these wate\n",
      "r they most greatly praised. And it is said by the Eldar that in water there lives yet the echo of the Music of the Ainur mor\n",
      "e than in any substance else that is in this Earth; and many of the Children of lluvatar hearken still unsated to the voices \n"
     ]
    }
   ],
   "source": [
    "start = 10505\n",
    "length = 500\n",
    "print(decode(data[start:start+length//4].tolist()))\n",
    "print(decode(data[start+length//4:start+length//4*2].tolist()))\n",
    "print(decode(data[start+length//4*2:start+length//4*3].tolist()))\n",
    "print(decode(data[start+length//4*3:start+length].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.85\n",
    "n = int(ratio*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169700, 559359)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataset and dataloader**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the unsupervisedTokenizedTextDataset takes in tokenized text (could be at character or word leve, or other level of tokenization), desired block size (input sequence length), predict_size (model output length: default 1 - use input sequence to predict the next token)\n",
    "\n",
    "the dataset will have length of len(full_txt) - (block_size+predict_size) +1\n",
    "\n",
    "for getitem, when given index\n",
    "txt[index], txt[index+1], ... txt[index+block_size - 1] will be input sequence with length block_size\n",
    "txt[index+block_size] ,..., txt[index+block_size+predict_size-1] will be output sequence with length predict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unsupervisedTokenizedTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,full_txt,block_size,predict_size=1):\n",
    "        self.txt = full_txt\n",
    "        self.block_size = block_size\n",
    "        self.predict_size = predict_size\n",
    "    def __len__(self):\n",
    "        return len(self.txt) - (self.block_size + self.predict_size) + 1\n",
    "    def __getitem__(self, idx):\n",
    "        input_sequence = self.txt[idx:idx+self.block_size]\n",
    "        output_sequence = self.txt[idx+self.block_size:idx+self.block_size+self.predict_size]\n",
    "        return input_sequence, output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 100\n",
    "output_size = 1\n",
    "\n",
    "train_dataset = unsupervisedTokenizedTextDataset(full_txt = train_data,\n",
    "                                                 block_size = block_size,\n",
    "                                                 predict_size=output_size)\n",
    "\n",
    "val_dataset = unsupervisedTokenizedTextDataset(full_txt = val_data,\n",
    "                                               block_size = block_size,\n",
    "                                               predict_size = output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169600, 559259)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sampler = torch.utils.data.RandomSampler(val_dataset,replacement=False,num_sample=2)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,batch_size=10,shuffle=True,sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e road. An hour long prepared approaches.' 'Don't leave me behind!' said Merry. 'I have not been of \n",
      "m\n"
     ]
    }
   ],
   "source": [
    "s_input, s_output = next(iter(train_dataloader))\n",
    "print(decode(s_input[1].tolist()))\n",
    "print(decode(s_output[1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
