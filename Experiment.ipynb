{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from operator import itemgetter\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Examining the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lord-of-the-rings-processed.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the book - 3729059 characters\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of the book - {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Music of the Ainur There was Eru, the One, who in Arda is called lluvatar; and he made first the\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '®', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '\"', \"'\", '®', '—', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "common = r\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ();:.!?-,\"\n",
    "special = [char for char in chars if char not in list(common)]\n",
    "print(special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\",\" \")\n",
    "text = text.replace(\"  \", \" \")\n",
    "text = text.replace(\"®\", \"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‘', '’', '“', '”', ',', ';', ':', '!', '?']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_char = list(itemgetter(*[6,7,8,9])(special))\n",
    "special_char.extend([\",\",\";\",\":\",\"!\",\"?\"])\n",
    "special_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‘', '“']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_space_after = list(itemgetter(*[0,2])(special_char))\n",
    "no_space_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['’', '”', ',', ';', ':', '!', '?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_space_before = list(itemgetter(*set(range(len(special_char)))-set([0,2]))(special_char))\n",
    "no_space_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace such as <' sss> to <'sss>\n",
    "for s in no_space_after:\n",
    "    text = text.replace(s+\" \", s)\n",
    "\n",
    "# replace such as <s ,> to <s,>\n",
    "for s in no_space_before:\n",
    "    text = text.replace(\" \"+s,s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the use of quotation marks\n",
    "text = text.replace('\"',\"'\")\n",
    "text = text.replace('‘',\"'\")\n",
    "text = text.replace('’',\"'\")\n",
    "text = text.replace('“',\"'\")\n",
    "text = text.replace('”',\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lord-of-the-rings-processed.txt\",\"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Create Dictionary and Tokenize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', \"'\", '—']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "common = r\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ();:.!?-,\"\n",
    "special = [char for char in chars if char not in list(common)]\n",
    "print(special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "encode_char = {char:i for i, char in enumerate(chars)}\n",
    "decode_char = {i:char for i, char in enumerate(chars)}\n",
    "print(len(encode_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda string: [encode_char[s] for s in string]\n",
    "decode = lambda nums: ''.join([decode_char[n] for n in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 54, 55, 65, 0, 55, 65, 0, 53, 61, 61, 50]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"This is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0?wXG'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([8,20,69,44,27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Load data and construct batches + dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3729059])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e filled with gladness; but because of the roaring of the sea they felt a great unquiet. And they observed the winds and the \n",
      "air, and the matters of which Arda was made, of iron and stone and silver and gold and many substances: but of all these wate\n",
      "r they most greatly praised. And it is said by the Eldar that in water there lives yet the echo of the Music of the Ainur mor\n",
      "e than in any substance else that is in this Earth; and many of the Children of lluvatar hearken still unsated to the voices \n"
     ]
    }
   ],
   "source": [
    "start = 10505\n",
    "length = 500\n",
    "print(decode(data[start:start+length//4].tolist()))\n",
    "print(decode(data[start+length//4:start+length//4*2].tolist()))\n",
    "print(decode(data[start+length//4*2:start+length//4*3].tolist()))\n",
    "print(decode(data[start+length//4*3:start+length].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.85\n",
    "n = int(ratio*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169700, 559359)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class slideTokenizedTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,full_txt,block_size):\n",
    "        self.txt = full_txt\n",
    "        self.block_size = block_size\n",
    "    def __len__(self):\n",
    "        return len(self.txt) - self.block_size\n",
    "    def __getitem__(self, idx):\n",
    "        input_sequence = self.txt[idx:idx+self.block_size]\n",
    "        output_sequence = self.txt[idx+1:idx+self.block_size+1]\n",
    "        return input_sequence, output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 500\n",
    "\n",
    "train_dataset = slideTokenizedTextDataset(full_txt = train_data,\n",
    "                                                 block_size = block_size)\n",
    "\n",
    "val_dataset = slideTokenizedTextDataset(full_txt = val_data,\n",
    "                                               block_size = block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169200, 558859)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num_samples = 200000\n",
    "val_sampler = torch.utils.data.RandomSampler(val_dataset,replacement=False,num_samples=val_num_samples)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,batch_size=batch_size,sampler=val_sampler,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to lose us,' he said. But at that moment Merry gave a whistle of relief and pointed ahead. 'Well, well!' he said. 'These trees do shift. There is the Bonfire Glade in front of us (or I hope so), but the path to it seems to have moved away!' The light grew clearer as they went forward. Suddenly they came out of the trees and found themselves in a wide circular space. There was sky above them, blue and clear to their surprise, for down under the Forest -roof they had not been able to see the risi\n",
      "to lose us,' he said. But at that moment Merry gave a whistle of relief and pointed ahead. 'Well, well!' he said. 'These trees do shift. There is the Bonfire Glade in front of us (or I hope so), but the path to it seems to have moved away!' The light grew clearer as they went forward. Suddenly they came out of the trees and found themselves in a wide circular space. There was sky above them, blue and clear to their surprise, for down under the Forest -roof they had not been able to see the risin\n"
     ]
    }
   ],
   "source": [
    "s_input, s_output = next(iter(train_dataloader))\n",
    "print(decode(s_input[2].tolist()))\n",
    "print(decode(s_output[2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24759, 1562)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for self-attention calculation from a single head\n",
    "# take input x, project to Q,K,V, apply the self-attention formula (Q @ K.T / sqrt(head_size)) @ V\n",
    "# in addition, the class takes an input decoder - it signals whether it is a encoder head or decoder head, decoder head has an additional mask step\n",
    "# input: [B, T, C] --> [B, T, H], where for multi-head attention, H = C / num_heads, C = emb_dim\n",
    "class Head(torch.nn.Module):\n",
    "    def __init__(self,emb_dim,head_size,block_size,dropout_rate,is_decoder):\n",
    "        super().__init__()\n",
    "        self.H = head_size\n",
    "        self.key = torch.nn.Linear(emb_dim,head_size,bias=False) # not including bias because of layer norm include bias term\n",
    "        self.query = torch.nn.Linear(emb_dim,head_size,bias=False)\n",
    "        self.value = torch.nn.Linear(emb_dim,head_size,bias=False)\n",
    "        if is_decoder:\n",
    "            self.register_buffer(\"tril_mat\", torch.tril(torch.ones(block_size,block_size))) # parameters not being updated\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.is_decoder = is_decoder\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B, T, C = x.shape # decompose dimensions: Batch, Time, Embedding\n",
    "        k = self.key(x) # B, T, H\n",
    "        q = self.query(x) # B, T, H\n",
    "        attention_W = q @ k.transpose(-2, -1) * self.H**-0.5 # B, T, T\n",
    "        if self.is_decoder:\n",
    "            attention_W = attention_W.masked_fill(self.tril_mat==0, float('-inf')) # B, T, T\n",
    "        attention_W = torch.nn.functional.softmax(attention_W,dim=-1)  # B, T, T\n",
    "        attention_W = self.dropout(attention_W)\n",
    "        v = self.value(x) # B, T, H\n",
    "        output = attention_W @ v # B, T, H\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for orchestrate multiple heads for multiple self-attention calculation\n",
    "# input: [B, T, C] --> output: [B, T, C]\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads, head_size, block_size,dropout_rate, is_decoder):\n",
    "        super().__init__()\n",
    "        self.heads = torch.nn.ModuleList([Head(emb_dim,head_size,block_size,dropout_rate,is_decoder) for _ in range(num_heads)])\n",
    "        self.projection = torch.nn.Linear(emb_dim,emb_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "    def forward(self,x):\n",
    "        output = torch.cat([h(x) for h in self.heads],dim=-1)\n",
    "        output = self.projection(output)\n",
    "        output = self.dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedforward network after multi-head attention: multiplier parameter is the number of times of neurons in hidden layer than input, default is 4 from the paper\n",
    "# input [B, T, C] --> output [B, T, C]\n",
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self,emb_dim,dropout_rate,multiplier):\n",
    "        super().__init__()\n",
    "        self.fflayer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(emb_dim, multiplier * emb_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(multiplier * emb_dim, emb_dim),\n",
    "            torch.nn.Dropout(p=dropout_rate)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        output = self.fflayer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for a transformer block: multi-head attention + feed forward + layer norm + residual connection\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self,emb_dim,num_heads,block_size,dropout_rate_attention,dropout_rate_ff,is_decoder=True,ff_multiplier=4):\n",
    "        super().__init__()\n",
    "        assert emb_dim % num_heads == 0, \"number of heads must be divisible by embedding dimention to determine the head size\"\n",
    "        head_size = emb_dim // num_heads\n",
    "        self.multi_atten = MultiHeadAttention(emb_dim = emb_dim, num_heads = num_heads, head_size = head_size, block_size = block_size,\n",
    "                                              dropout_rate = dropout_rate_attention, is_decoder = is_decoder)\n",
    "        self.feedforward = FeedForward(emb_dim = emb_dim, dropout_rate = dropout_rate_ff,multiplier = ff_multiplier)\n",
    "        self.layernorm1 = torch.nn.LayerNorm(emb_dim)\n",
    "        self.layernorm2 = torch.nn.LayerNorm(emb_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = x + self.multi_atten(self.layernorm1(x)) # layer norm + multi-head attention + residual\n",
    "        output =  output + self.feedforward(self.layernorm2(output)) # layer norm + feed forward + residual\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = np.zeros((3,2))\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = np.zeros(6)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = pe.reshape(3,2)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
