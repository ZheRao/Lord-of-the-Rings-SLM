{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0656ce1-bc50-4562-b706-aa5cab2964f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from operator import itemgetter\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from update_utilities import update_utilities_class\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47cb3e11-ce7c-4801-9292-f5baea6f8360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "with open('saved_encoder_dict.pkl','rb') as f:\n",
    "    encode_char = pickle.load(f)\n",
    "\n",
    "with open('saved_decoder_dict.pkl','rb') as f:\n",
    "    decode_char = pickle.load(f)\n",
    "\n",
    "print(len(encode_char))\n",
    "vocab_size = len(encode_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25eda12e-9294-44d3-9fad-ab363a192e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda string: [encode_char[s] for s in string]\n",
    "decode = lambda nums: ''.join([decode_char[n] for n in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e413bb-5820-4625-bd09-babebeb29bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Transformer\n",
    "block_size=512\n",
    "device='cpu'\n",
    "transformer = Transformer.TransformerClass(vocab_size=vocab_size,emb_dim=512,n_layer=8,num_heads=8,block_size=block_size,\n",
    "                               dropout_rate_attention=0.1,dropout_rate_ff=0.2,dropout_rate_pos_enc=0.1, \n",
    "                               is_decoder = True, ff_multiplier = 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45596801-26ad-42a3-9bbb-e7b916de5137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.28 M parameters\n"
     ]
    }
   ],
   "source": [
    "print(round(sum(p.numel() for p in transformer.parameters())/1e6,2), 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf70fb61-23fc-4d66-8f47-c742e4f2f7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load(\"base_line_GPT stats/base_line_GPT weights/base_line_GPT_last.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fdb48f-2f56-48b9-9255-696b975779c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,max_new_tokens,encoder,decoder,block_size=512):\n",
    "    print(f\"Please enter some text to start the text generation, ideally the length you type is between 20 and 50 words, model will generate {max_new_tokens} characters\\n\")\n",
    "    user_input = input(f\"Enter here: \")\n",
    "    input_encode = torch.tensor(encoder(user_input))\n",
    "    output = list(input_encode)\n",
    "    if len(input_encode) < block_size:\n",
    "        pad_length = block_size - len(input_encode)\n",
    "        idx = torch.zeros((1,block_size),dtype=torch.long)\n",
    "        idx[:,pad_length:] = input_encode\n",
    "        #print(decoder(idx.squeeze().tolist()))\n",
    "    else:\n",
    "        idx = input_encode[-block_size:].unsqueeze(0)\n",
    "        #print(decoder(idx.squeeze().tolist()))\n",
    "    \n",
    "    print_status = False\n",
    "    print_index_start = len(output)\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Generating..........................\\n\")\n",
    "    sentence_end = encoder(\".!?' \")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        if len(output) % 100 == 0:\n",
    "            print_status = True\n",
    "        if print_status and output[-1] in sentence_end:\n",
    "            print_setence = decoder(output[print_index_start:])\n",
    "            print_index_start = len(output)\n",
    "            print_status=False\n",
    "            print(print_setence + \"\\n\")\n",
    "        idx_cond = idx[:,-block_size:]\n",
    "        logits = model(idx_cond) # B, T, vocab_size\n",
    "        logits = logits[:,-1,:] # logits for the last character\n",
    "        probs = torch.nn.functional.softmax(logits.squeeze(),dim=0)\n",
    "        idx_next = torch.multinomial(probs,num_samples=1)\n",
    "        output.append(idx_next.squeeze().item())\n",
    "        idx = torch.cat((idx,idx_next.unsqueeze(0)),dim=1)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8442ea-c535-4c1d-8893-b75089294895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter some text to start the text generation, ideally the length you type is between 20 and 50 words, model will generate 2000 characters\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter here:  Legolas and Aragorn sitting in a tree. Kissing. Legolas looks sad that Aragorn has not yet left Arwen. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating..........................\n",
      "\n",
      "They passed their hands and looked out of silence towards them. The precious things had begun in \n",
      "\n",
      "the days of Anar they had been written by some gifty leaves. As their eyes grew the truth. Luthien, \n",
      "\n",
      "feared that now clear was the darkness of evening summer, and the fall of Turin as it seemed the oathbreaker \n",
      "\n",
      "to were beneath him. By the right they could all be, and Turin knew their weapons died in Nan \n",
      "\n",
      "Elmoth, and there many of the Trees being woke in a stride, and there fell Curufin gate fell upon \n",
      "\n",
      "his head, and on the saddle of Turin, and treachery did his tatter in torment; and his eyes shining \n",
      "\n",
      "in the body and skill the blades of Doriath. By the starlit mere was gleamed with two flowers of manhood, \n",
      "\n",
      "and King Thingol gave there to the sons of Finrod; but still Beleg watched ever and came over \n",
      "\n",
      "the mountains There in the night there mantled all the houses of Thingol, and drew forth even to Doriath, \n",
      "\n",
      "seeking vessels for peril. For the Naugrim declared that they had proved war, Derenho the deeds \n",
      "\n",
      "of Thingol had deceived Melian, and for them came thither; and since Nessa to Belegost, the Great \n",
      "\n",
      "House, be hangered of the Valar. But after the dead of Anglach the Noldor to Middle-earth Aman were \n",
      "\n",
      "afoot, and though he loved beyond all pursue foes that was briefly kind. Thus Arda; but Naeglach remained \n",
      "\n",
      "in Estolad, for they returned with all that was ease under the shadow of Morgoth. Thus ended \n",
      "\n",
      "the shores and desire of Melian, that fled was valiant from the remnant of that place of the Noldor \n",
      "\n",
      "so time did great evil. Of those Finarfin was the welcome of life in Doriath, and the birds sat strong \n",
      "\n",
      "alone in bodies, and gathering them upon his head the northern land of Doriath; and Orome had sent \n",
      "\n",
      "himself to whom the Teleri spoke with them, and he feared to forsake them in seeking for his gates; \n",
      "\n",
      "for they were trapped even to banish on the fields of Tumladen, seeing the great captains of Angband.\n",
      "\n",
      " Between Dor and Beleg already and Nimrodel of the woodmen were wounded to them, foreboding their \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate(transformer,2000,encoder = encode, decoder = decode,block_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c01f858d-f4f9-4d2c-8d26-fa5c097a752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512, 74])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(70, (100,))\n",
    "pad_length = 512 - len(a)\n",
    "idx = torch.zeros((1,block_size),dtype=torch.long)\n",
    "idx[:,pad_length:] = a\n",
    "print(idx.shape)\n",
    "b = transformer(idx)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11d8d4ca-e480-4ddd-b345-4f9668dd71b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([74])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = b[:,-1,:].squeeze()\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d5246b0-cd6d-40c2-ad53-8ca96f81df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.6646,  4.8699,  0.5909, -1.1043,  4.5587,  4.2549,  2.8798,  6.3165,\n",
       "         6.9580,  3.1944,  7.9979,  3.0714,  7.6264,  2.1841,  5.2547,  2.5160,\n",
       "         5.5916,  5.4049,  3.4680,  0.3700,  2.4109,  3.1376,  2.5324,  0.3565,\n",
       "         2.3291,  8.1200,  4.0588,  2.1128,  2.5585,  3.4352, -0.9041,  0.8907,\n",
       "         2.9982,  3.0420,  4.4203,  5.7570,  2.0232,  3.7661,  2.8905,  3.5078,\n",
       "         4.2205,  0.7041,  3.2672,  1.9475,  1.5920,  5.3364, -0.4227, -0.8958,\n",
       "        -1.7573, -4.9720, -3.4157,  3.1858, -2.9820, -0.9897, -1.8671, -7.1939,\n",
       "         4.2730, -3.0023, -5.3467, -1.6149, -4.3354,  1.3004, -1.3381, -2.5372,\n",
       "        -4.8071, -1.4945, -4.1417,  2.1203, -2.7545,  0.3176, -2.0061, -6.9457,\n",
       "         2.3136, -1.0229], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43233457-0b0c-465b-81a3-87a69a3c8c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3017e-02, 1.0397e-02, 1.4407e-04, 2.6447e-05, 7.6165e-03, 5.6214e-03,\n",
       "        1.4212e-03, 4.4175e-02, 8.3902e-02, 1.9466e-03, 2.3734e-01, 1.7212e-03,\n",
       "        1.6371e-01, 7.0876e-04, 1.5277e-02, 9.8775e-04, 2.1398e-02, 1.7753e-02,\n",
       "        2.5591e-03, 1.1552e-04, 8.8920e-04, 1.8391e-03, 1.0041e-03, 1.1396e-04,\n",
       "        8.1939e-04, 2.6818e-01, 4.6201e-03, 6.5998e-04, 1.0306e-03, 2.4766e-03,\n",
       "        3.2309e-05, 1.9443e-04, 1.5997e-03, 1.6714e-03, 6.6324e-03, 2.5246e-02,\n",
       "        6.0342e-04, 3.4480e-03, 1.4365e-03, 2.6631e-03, 5.4310e-03, 1.6134e-04,\n",
       "        2.0935e-03, 5.5940e-04, 3.9205e-04, 1.6578e-02, 5.2288e-05, 3.2576e-05,\n",
       "        1.3764e-05, 5.5290e-07, 2.6214e-06, 1.9299e-03, 4.0448e-06, 2.9658e-05,\n",
       "        1.2334e-05, 5.9933e-08, 5.7238e-03, 3.9636e-06, 3.8012e-07, 1.5872e-05,\n",
       "        1.0450e-06, 2.9290e-04, 2.0932e-05, 6.3107e-06, 6.5200e-07, 1.7902e-05,\n",
       "        1.2684e-06, 6.6493e-04, 5.0778e-06, 1.0962e-04, 1.0733e-05, 7.6817e-08,\n",
       "        8.0678e-04, 2.8689e-05], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.nn.functional.softmax(logits,dim=0)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42d8a57a-15ed-4b38-96de-1d37af131683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([[10]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d = torch.multinomial(probs,num_samples=1).unsqueeze(0)\n",
    "print(d.shape)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "da51a6a5-9eed-4da2-85a8-0139193a0b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.squeeze().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913b3b3-76ae-414a-998d-9b180b4361a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
